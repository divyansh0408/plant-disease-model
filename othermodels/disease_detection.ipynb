{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e04cfdb-615e-4d29-b1b4-0d0358652912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efd744a-4dbe-48e2-bb06-89afd747cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize images to the range [0, 1]\n",
    "    rotation_range=30,  # Random rotations\n",
    "    width_shift_range=0.2,  # Random horizontal shifts\n",
    "    height_shift_range=0.2,  # Random vertical shifts\n",
    "    shear_range=0.2,  # Random shearing\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    horizontal_flip=True,  # Random horizontal flips\n",
    "    fill_mode='nearest'  # Fill any pixels after transformations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9aade2-7a36-41ec-93aa-1b7cc0bfb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4eab4a6-afe5-4f2b-8f23-99abfb313614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"D:\\Dataset\\train\"  # Update with your path\n",
    "valid_dir = r\"D:\\Dataset\\valid\"  # Update with your "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7718e620-21f8-4a2f-9d51-2595de8bdc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15447 images belonging to 42 classes.\n",
      "Found 3171 images belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),  # Resize images to 128x128\n",
    "    batch_size=32,  # Batch size\n",
    "    class_mode='categorical'  # Multi-class classification (healthy, powdery, rust)\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(64, 64),  # Resize images to 128x128\n",
    "    batch_size=32,  # Batch size\n",
    "    class_mode='categorical'  # Multi-class classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45618ee3-eb0c-4e80-a21b-24ac0b44297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['American Bollworm on Cotton', 'Anthracnose on Cotton', 'Army worm', 'Becterial Blight in Rice', 'Brownspot', 'Common_Rust', 'Cotton Aphid', 'Flag Smut', 'Gray_Leaf_Spot', 'Healthy Maize', 'Healthy Wheat', 'Healthy cotton', 'Leaf Curl', 'Leaf smut', 'Mosaic sugarcane', 'RedRot sugarcane', 'RedRust sugarcane', 'Rice Blast', 'Sugarcane Healthy', 'Tungro', 'Wheat Brown leaf Rust', 'Wheat Stem fly', 'Wheat aphid', 'Wheat black rust', 'Wheat leaf blight', 'Wheat mite', 'Wheat powdery mildew', 'Wheat scab', 'Wheat___Yellow_Rust', 'Wilt', 'Yellow Rust Sugarcane', 'bacterial_blight in Cotton', 'bollrot on Cotton', 'bollworm on Cotton', 'cotton mealy bug', 'cotton whitefly', 'maize ear rot', 'maize fall armyworm', 'maize stem borer', 'pink bollworm in cotton', 'red cotton bug', 'thirps on  cotton']\n"
     ]
    }
   ],
   "source": [
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(\"Class Names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5341e1d8-11fa-4014-a8a3-588355b0bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e71a7e9-9006-4146-82a6-28306ddb3fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(42, activation='softmax'))  # Match your class count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "249c9c61-6ed2-41bb-b4ad-5a9ba52cc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Multi-class classification\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b347a42f-ed55-496f-a375-33023fba8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201bff08-d684-4559-8ef7-389e6dd9aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m130/483\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:53\u001b[0m 830ms/step - accuracy: 0.1848 - loss: 3.0691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2910 - loss: 2.6936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:935: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 1s/step - accuracy: 0.2911 - loss: 2.6930 - val_accuracy: 0.0442 - val_loss: 4.9804\n",
      "Epoch 2/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 691ms/step - accuracy: 0.4940 - loss: 1.8358 - val_accuracy: 0.0527 - val_loss: 4.6503\n",
      "Epoch 3/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 666ms/step - accuracy: 0.5813 - loss: 1.5479 - val_accuracy: 0.0489 - val_loss: 5.4415\n",
      "Epoch 4/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 681ms/step - accuracy: 0.6349 - loss: 1.3094 - val_accuracy: 0.0382 - val_loss: 6.1879\n",
      "Epoch 5/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 618ms/step - accuracy: 0.6769 - loss: 1.1677 - val_accuracy: 0.0552 - val_loss: 6.3464\n",
      "Epoch 6/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 615ms/step - accuracy: 0.7155 - loss: 1.0330 - val_accuracy: 0.0637 - val_loss: 6.1075\n",
      "Epoch 7/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 614ms/step - accuracy: 0.7486 - loss: 0.9190 - val_accuracy: 0.0710 - val_loss: 6.7751\n",
      "Epoch 8/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 602ms/step - accuracy: 0.7432 - loss: 0.9063 - val_accuracy: 0.0605 - val_loss: 7.6382\n",
      "Epoch 9/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 623ms/step - accuracy: 0.7708 - loss: 0.8232 - val_accuracy: 0.0621 - val_loss: 7.1930\n",
      "Epoch 10/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 624ms/step - accuracy: 0.7838 - loss: 0.7723 - val_accuracy: 0.0706 - val_loss: 8.0206\n",
      "Epoch 11/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 973ms/step - accuracy: 0.7913 - loss: 0.7346 - val_accuracy: 0.0624 - val_loss: 7.8432\n",
      "Epoch 12/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 579ms/step - accuracy: 0.8056 - loss: 0.7010 - val_accuracy: 0.0741 - val_loss: 8.4225\n",
      "Epoch 13/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 580ms/step - accuracy: 0.8095 - loss: 0.6632 - val_accuracy: 0.0801 - val_loss: 8.8691\n",
      "Epoch 14/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 561ms/step - accuracy: 0.8200 - loss: 0.6383 - val_accuracy: 0.1041 - val_loss: 9.2602\n",
      "Epoch 15/15\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 575ms/step - accuracy: 0.8269 - loss: 0.6167 - val_accuracy: 0.0798 - val_loss: 8.7960\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,  # Start with 20 epochs, adjust as needed\n",
    "    validation_data=valid_generator,\n",
    "    # callbacks=[early_stopping, checkpoint],  # Apply early stopping and checkpoint\n",
    "    verbose=1  # Show progress during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa883906-c4c8-45c7-999e-2495294aa460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('disease_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4020b1-4674-4267-9108-37ad7da4615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.3%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(valid_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
